{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logo.png'>\n",
    "<img src='img/title.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers \"pipelines\" or machine learning workflows that are expressed as a sequence of named steps with parameters that may be varied in a grid or randomized search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Pipelines](#Pipelines)\n",
    "\t* [Algorithm chains and pipelines](#Algorithm-chains-and-pipelines)\n",
    "\t\t* [Building pipelines](#Building-pipelines)\n",
    "\t\t\t* [Another Pipeline example](#Another-Pipeline-example)\n",
    "\t\t\t* [And here it is with a Pipeline](#And-here-it-is-with-a-Pipeline)\n",
    "\t\t* [The General Pipeline Interface](#The-General-Pipeline-Interface)\n",
    "\t\t* [Pipeline attributes](#Pipeline-attributes)\n",
    "\t\t\t* [Access by name](#Access-by-name)\n",
    "* [Summary](#Summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix working directory\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.interpolation'] = \"none\"\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "import src.mglearn as mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm chains and pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells show a pipeline workflow written out in declarative form with the tools we have covered so far, including `MinMaxScaler` for scaling, and `GridSearchCV` for model selection with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split the data\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute minimum and maximum on the training data\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "# rescale training data\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma='auto')\n",
    "# learn an SVM on the scaled training data\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "# scale test data and score the scaled data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "svm.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pipe = make_pipeline(` in the next cell is a shorter way of expressing the logic in the cells above.  It creates a `Pipeline` with two named steps, `'minmaxascaler'` and `'svc'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC(gamma='auto'))\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe has an interface like SVC() but the \"fit\" method is inclusive of pipeline steps\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another Pipeline example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with 100 rows and 10,000 columns of random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.RandomState(seed=0)\n",
    "X = rnd.normal(size=(100, 10000))\n",
    "y = rnd.normal(size=(100,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SelectPercentile` feature selctor as first step, the `Ridge` regression (regression with `L2` norm penalty).\n",
    "\n",
    "Select the top 5% of the features with the lowest f_regression sore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "\n",
    "select = SelectPercentile(score_func=f_regression, percentile=5).fit(X, y)\n",
    "X_selected = select.transform(X)\n",
    "print(X_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform cross validation we need to fit and transform each fold separately.\n",
    "\n",
    "First, here's how it would be done delcaratively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold5 = KFold(5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "scores = np.empty(0)\n",
    "for train, test in kfold5.split(X):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test  = X[test]\n",
    "    y_test  = y[test]\n",
    "    \n",
    "    selector = SelectPercentile(score_func=f_regression, percentile=5).fit(X_train, y_train)\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    score = Ridge().fit(X_train_selected, y_train).score(X_test_selected, y_test)\n",
    "    scores = np.append(scores, score)\n",
    "    \n",
    "    \n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And here it is with a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipe = make_pipeline(SelectPercentile(score_func=f_regression, percentile=5), Ridge())\n",
    "scores = cross_val_score(pipe, X, y, cv=kfold5.split(X))\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The General Pipeline Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/pipeline-diagram.png\" align='right' alt=\"Pipeline Illustration\" width=\"43%\"/>\n",
    "\n",
    "```python\n",
    "def fit(self, X, y):\n",
    "    X_transformed = X\n",
    "    for step in self.steps[:-1]:\n",
    "        # iterate over all but the final step\n",
    "        # fit and transform the data\n",
    "        X_transformed = step[1].fit_transform(X_transformed, y)\n",
    "    # fit the last step\n",
    "    self.steps[-1][1].fit(X_transformed, y)\n",
    "    return self\n",
    "\n",
    "def predict(self, X):\n",
    "    X_transformed = X\n",
    "    for step in self.steps[:-1]:\n",
    "        # iterate over all but the final step\n",
    "        # transform the data\n",
    "        X_transformed = step[1].transform(X_transformed)\n",
    "    # fit the last step\n",
    "    return self.steps[-1][1].predict(X_transformed)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image: CC-BY-NA, [Karl Rosaen](http://karlrosaen.com/ml/learning-log/2016-06-20/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), PCA(n_components=2), SVC(gamma='auto', C=100))\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(cancer.data, cancer.target)\n",
    "\n",
    "components = pipe.named_steps[\"pca\"].components_\n",
    "print(components.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we reviewed the following topics in preparation for more advanced topics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * [Algorithm chains and pipelines](#Algorithm-Chains-and-Pipelines)\n",
    " * [The general pipeline interface](#The-General-Pipeline-Interface)\n",
    " * [Accessing step attributes](#Accessing-step-attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/copyright.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [module-machine-learning]",
   "language": "python",
   "name": "anaconda-project-module-machine-learning-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
